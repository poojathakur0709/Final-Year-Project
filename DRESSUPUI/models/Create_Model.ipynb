{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.layers.experimental.preprocessing import StringLookup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.image as mpimg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 6044: expected 10 fields, saw 11\\nSkipping line 6569: expected 10 fields, saw 11\\nSkipping line 7399: expected 10 fields, saw 11\\nSkipping line 7939: expected 10 fields, saw 11\\nSkipping line 9026: expected 10 fields, saw 11\\nSkipping line 10264: expected 10 fields, saw 11\\nSkipping line 10427: expected 10 fields, saw 11\\nSkipping line 10905: expected 10 fields, saw 11\\nSkipping line 11373: expected 10 fields, saw 11\\nSkipping line 11945: expected 10 fields, saw 11\\nSkipping line 14112: expected 10 fields, saw 11\\nSkipping line 14532: expected 10 fields, saw 11\\nSkipping line 15076: expected 10 fields, saw 12\\nSkipping line 29906: expected 10 fields, saw 11\\nSkipping line 31625: expected 10 fields, saw 11\\nSkipping line 33020: expected 10 fields, saw 11\\nSkipping line 35748: expected 10 fields, saw 11\\nSkipping line 35962: expected 10 fields, saw 11\\nSkipping line 37770: expected 10 fields, saw 11\\nSkipping line 38105: expected 10 fields, saw 11\\nSkipping line 38275: expected 10 fields, saw 11\\nSkipping line 38404: expected 10 fields, saw 12\\n'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Casual', 'Ethnic', 'Formal', 'Sports', nan, 'Smart Casual',\n",
       "       'Travel', 'Party', 'Home'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "styles = pd.read_csv(\"D:/Btech/college/SEM7/archive (1)/styles.csv\", error_bad_lines=False)\n",
    "styles[\"usage\"].unique()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_drop(styles, col, item):\n",
    "    \"\"\"\n",
    "    This function drops certain columns\n",
    "    input: styles, dataframe\n",
    "        col, the item we want to drop in this coloumn\n",
    "        item, which item we want to drop \n",
    "    \"\"\"\n",
    "    for i in item:\n",
    "        styles = styles.drop(styles[styles[col] == i].index)\n",
    "    return styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 6044: expected 10 fields, saw 11\\nSkipping line 6569: expected 10 fields, saw 11\\nSkipping line 7399: expected 10 fields, saw 11\\nSkipping line 7939: expected 10 fields, saw 11\\nSkipping line 9026: expected 10 fields, saw 11\\nSkipping line 10264: expected 10 fields, saw 11\\nSkipping line 10427: expected 10 fields, saw 11\\nSkipping line 10905: expected 10 fields, saw 11\\nSkipping line 11373: expected 10 fields, saw 11\\nSkipping line 11945: expected 10 fields, saw 11\\nSkipping line 14112: expected 10 fields, saw 11\\nSkipping line 14532: expected 10 fields, saw 11\\nSkipping line 15076: expected 10 fields, saw 12\\nSkipping line 29906: expected 10 fields, saw 11\\nSkipping line 31625: expected 10 fields, saw 11\\nSkipping line 33020: expected 10 fields, saw 11\\nSkipping line 35748: expected 10 fields, saw 11\\nSkipping line 35962: expected 10 fields, saw 11\\nSkipping line 37770: expected 10 fields, saw 11\\nSkipping line 38105: expected 10 fields, saw 11\\nSkipping line 38275: expected 10 fields, saw 11\\nSkipping line 38404: expected 10 fields, saw 12\\n'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Topwear', 'Bottomwear', 'Footwear'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####LOAD DATASET\n",
    "def get_df():\n",
    "    styles = pd.read_csv(\"D:/Btech/college/SEM7/archive (1)/styles.csv\", error_bad_lines=False)\n",
    "    styles = styles.drop([\"productDisplayName\"],axis = 1) #drop useless column, we do not need name to do recommendation\n",
    "    styles = styles.drop([\"year\"],axis = 1) #drop useless column, we do not need year to do recommendation\n",
    "    styles = styles[(styles.masterCategory=='Apparel')| (styles.masterCategory=='Footwear')] # drop useless rows, we are not recommend acessories\n",
    "    styles = styles.drop(styles[styles[\"subCategory\"] == \"Innerwear\"].index) # drop useless row, we are not recommend innerwears, only outfits.\n",
    "    styles = styles.dropna() # drop NA\n",
    "    styles = df_drop(styles,\"subCategory\", [\"Apparel Set\", \"Dress\",\"Loungewear and Nightwear\",\"Saree\",\"Socks\"]) # we only recommend outfits.\n",
    "    styles[\"subCategory\"] = styles[\"subCategory\"].transform(lambda x: \"Footwear\" if(x in [\"Shoes\",\"Flip Flops\",\"Sandal\"]) else x) # Group them into one category.\n",
    "    styles = styles.drop(labels=[6695,16194,32309,36381,40000], axis=0) # drop incomplete rows\n",
    "    return styles\n",
    "\n",
    "styles = get_df()\n",
    "#styles.head()\n",
    "styles[\"subCategory\"].unique() # we can check by this code that we only have three subcategory now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>masterCategory</th>\n",
       "      <th>subCategory</th>\n",
       "      <th>articleType</th>\n",
       "      <th>baseColour</th>\n",
       "      <th>season</th>\n",
       "      <th>usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15970</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>2</td>\n",
       "      <td>Shirts</td>\n",
       "      <td>Navy Blue</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39386</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>0</td>\n",
       "      <td>Jeans</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21379</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>0</td>\n",
       "      <td>Track Pants</td>\n",
       "      <td>Black</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53759</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>2</td>\n",
       "      <td>Tshirts</td>\n",
       "      <td>Grey</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1855</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>2</td>\n",
       "      <td>Tshirts</td>\n",
       "      <td>Grey</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Casual</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id gender masterCategory  subCategory  articleType baseColour  season  \\\n",
       "0  15970    Men        Apparel            2       Shirts  Navy Blue    Fall   \n",
       "1  39386    Men        Apparel            0        Jeans       Blue  Summer   \n",
       "3  21379    Men        Apparel            0  Track Pants      Black    Fall   \n",
       "4  53759    Men        Apparel            2      Tshirts       Grey  Summer   \n",
       "5   1855    Men        Apparel            2      Tshirts       Grey  Summer   \n",
       "\n",
       "    usage  \n",
       "0  Casual  \n",
       "1  Casual  \n",
       "3  Casual  \n",
       "4  Casual  \n",
       "5  Casual  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Model-1: \"\"\"\n",
    "\n",
    "le = LabelEncoder()\n",
    "#\n",
    "styles[\"subCategory\"] = le.fit_transform(styles[\"subCategory\"])\n",
    "\n",
    "styles.head()\n",
    "\n",
    "#styles[\"articleType\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bottomwear', 'Footwear', 'Topwear'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_array_subcate(df):\n",
    "\n",
    "    train_images = np.zeros((len(df.id),80,60,3))\n",
    "    for i in range(len(df.id)):\n",
    "        \n",
    "        try:\n",
    "            ID = df.id.iloc[i]\n",
    "            path = f\"D:/Btech/college/SEM7/archive (1)/images/{ID}.jpg\"#/content/images   \n",
    "            img = cv2.imread(path)\n",
    "            if img.shape != (80,60,3):#DESIRED SHAPE\n",
    "                img = image.load_img(path, target_size=(80,60,3))\n",
    "\n",
    "        except:\n",
    "            print(ID)\n",
    "        \n",
    "        train_images[i] = img\n",
    "\n",
    "    data = tf.data.Dataset.from_tensor_slices(\n",
    "      (\n",
    "        {\n",
    "          \"images\" : train_images\n",
    "       },\n",
    "\n",
    "        {\n",
    "          \"subCategory\" : df[[\"subCategory\"]]\n",
    "        }\n",
    "      )\n",
    "    )\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_xx(x):\n",
    "    \n",
    "    #make_input_array_subcate(styles)\n",
    "    print(\"make input\")\n",
    "    x_input = x\n",
    "    x_input = x_input.shuffle(buffer_size = len(x_input))\n",
    "\n",
    "    x_train_size = int(0.6*len(x_input))\n",
    "    x_val_size   = int(0.2*len(x_input))\n",
    "\n",
    "    x_train = x_input.take(x_train_size).batch(2)\n",
    "    x_val   = x_input.skip(x_train_size).take(x_val_size).batch(2)\n",
    "    x_test  = x_input.skip(x_train_size + x_val_size).batch(2)\n",
    "\n",
    "    return x_train,x_val,x_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_branch(res_input, n_out, act_type, name):\n",
    "    z = layers.Dense(512, activation=\"relu\")(res_input)\n",
    "    z = layers.Dense(256, activation='relu')(z)\n",
    "    z = layers.Dense(128, activation='relu')(z)\n",
    "    z = layers.Dense(64, activation='relu')(z)\n",
    "    z = layers.Dense(n_out)(z)\n",
    "    z = layers.Activation(act_type, name=name)(z)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(width, height):\n",
    "    res50 = keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(80,60,3))\n",
    "    res50.trainable=False\n",
    "    inputs = keras.Input(shape=(width,height,3),name = \"images\")\n",
    "    x = res50(inputs, training=False)\n",
    "    x = layers.Conv2D(32, (2, 2), activation='relu')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(1024, activation='relu')(x)\n",
    "    # -------------------------\n",
    "\n",
    "    sub_branch = make_branch(x, len(le.classes_), 'softmax', 'subCategory')\n",
    "\n",
    "    model = keras.Model(inputs=inputs,\n",
    "                outputs=[sub_branch]\n",
    "                       )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train,sub_val,sub_test = make_input_xx(make_input_array_subcate(styles))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sub_model = build_model(80, 60)\n",
    "\n",
    "sub_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(sub_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "sub_history = sub_model.fit(sub_train, \n",
    "                    epochs=5, \n",
    "                    steps_per_epoch = 2000,\n",
    "                    validation_data = sub_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub_model.save(\"model_sub\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = tf.keras.models.load_model(\"model_sub\")\n",
    "\n",
    "test_model.evaluate(sub_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_234_df(x):\n",
    "    styles = pd.read_csv(\"D:/Btech/college/SEM7/archive (1)/styles.csv\", error_bad_lines=False)\n",
    "    styles = styles.drop([\"productDisplayName\"],axis = 1)\n",
    "    styles = styles.drop([\"year\"],axis = 1)\n",
    "    styles = styles[(styles.masterCategory=='Apparel')| (styles.masterCategory=='Footwear')]\n",
    "    styles = styles.drop(styles[styles[\"subCategory\"] == \"Innerwear\"].index)\n",
    "    styles = styles.dropna()\n",
    "    styles = df_drop(styles,\"subCategory\", [\"Apparel Set\", \"Dress\",\"Loungewear and Nightwear\",\"Saree\",\"Socks\"])\n",
    "    styles[\"subCategory\"] = styles[\"subCategory\"].transform(lambda x: \"Footwear\" if(x in [\"Shoes\",\"Flip Flops\",\"Sandal\"]) else x)\n",
    "    styles = styles.drop(labels=[6695,16194,32309,36381,40000], axis=0)\n",
    "    styles = styles[styles.subCategory == x]\n",
    "    return styles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_df = get_234_df(\"Topwear\")\n",
    "bottom_df = get_234_df(\"Bottomwear\")\n",
    "foot_df = get_234_df(\"Footwear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_le(styles):\n",
    "    articleTypeLB = LabelEncoder()\n",
    "    genderLB = LabelEncoder()\n",
    "    baseColourLB = LabelEncoder()\n",
    "    seasonLB = LabelEncoder()\n",
    "    usageLB = LabelEncoder()\n",
    "\n",
    "    styles['articleType'] = articleTypeLB.fit_transform(styles['articleType'])\n",
    "    styles['gender'] = genderLB.fit_transform(styles['gender'])\n",
    "    styles['baseColour'] = baseColourLB.fit_transform(styles['baseColour'])\n",
    "    styles['season'] = seasonLB.fit_transform(styles['season'])\n",
    "    styles['usage'] = usageLB.fit_transform(styles['usage'])\n",
    "    return styles,articleTypeLB,genderLB,baseColourLB,seasonLB,usageLB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_df,top_art,top_gen,top_base,top_sea,top_usage = my_le(top_df)\n",
    "bottom_df,bottom_art,bottom_gen,bottom_base,bottom_sea,bottom_usage = my_le(bottom_df)\n",
    "foot_df,foot_art,foot_gen,foot_base,foot_sea,foot_usage = my_le(foot_df)\n",
    "\n",
    "foot_usage.classes_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(width, height, articleTypeLB,genderLB,baseColourLB,seasonLB,usageLB):\n",
    "    \"\"\"\n",
    "    build the machine learning model. similar to the previous one\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------------\n",
    "    res50 = keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(80,60,3))\n",
    "    res50.trainable=False\n",
    "    inputs = keras.Input(shape=(width,height,3),name = \"images\")\n",
    "    x = res50(inputs, training=False)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(1024, activation='relu')(x)\n",
    "    # -------------------------\n",
    "\n",
    "    article_branch = make_branch(x, len(articleTypeLB.classes_), 'softmax', 'articleType')\n",
    "    gender_branch = make_branch(x, len(genderLB.classes_), 'softmax', 'gender')\n",
    "    color_branch = make_branch(x, len(baseColourLB.classes_), 'softmax', 'baseColour')\n",
    "    season_branch = make_branch(x, len(seasonLB.classes_), 'softmax', 'season')\n",
    "    usage_branch = make_branch(x, len(usageLB.classes_), 'softmax', 'usage')\n",
    "\n",
    "    model = keras.Model(inputs=inputs,\n",
    "                outputs=[article_branch, gender_branch, color_branch, \n",
    "                            season_branch, usage_branch]\n",
    "                       )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_base_model = build_model(80,60,top_art,top_gen,top_base,top_sea,top_usage)\n",
    "bottom_base_model = build_model(80,60,bottom_art,bottom_gen,bottom_base,bottom_sea,bottom_usage)\n",
    "foot_base_model = build_model(80,60,foot_art,foot_gen,foot_base,foot_sea,foot_usage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_array_2(df):\n",
    "    train_images = np.zeros((len(df.id),80,60,3))\n",
    "    for i in range(len(df.id)):\n",
    "        ID = df.id.iloc[i]\n",
    "        path = f\"D:/Btech/college/SEM7/archive (1)/images/{ID}.jpg\"#/content/images   \n",
    "        img = cv2.imread(path)\n",
    "        if img.shape != (80,60,3):\n",
    "            img = image.load_img(path, target_size=(80,60,3))\n",
    "        \n",
    "        train_images[i] = img\n",
    "    \n",
    "    data = tf.data.Dataset.from_tensor_slices(\n",
    "      (\n",
    "        {\n",
    "          \"images\" : train_images\n",
    "       },\n",
    "\n",
    "        {\n",
    "          \"articleType\" : df[[\"articleType\"]],\n",
    "            'gender' : df[['gender']],\n",
    "            'baseColour' : df[['baseColour']],\n",
    "            'season' : df[['season']],\n",
    "            'usage' : df[['usage']]\n",
    "            \n",
    "        }\n",
    "      )\n",
    "    )\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_train, top_val, top_test = make_input_xx(make_input_array_2(top_df))\n",
    "bottom_train, bottom_val, bottom_test = make_input_xx(make_input_array_2(bottom_df))\n",
    "foot_train, foot_val, foot_test = make_input_xx(make_input_array_2(foot_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_base_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "bottom_base_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "foot_base_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "top_history = top_base_model.fit(top_train, \n",
    "                    epochs=10, \n",
    "                    steps_per_epoch = 500,\n",
    "                    validation_data = top_val)\n",
    "\n",
    "top_base_model.evaluate(top_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_base_model.save(\"model_2.1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_history = bottom_base_model.fit(bottom_train, \n",
    "                    epochs=15, \n",
    "                    steps_per_epoch = 50,\n",
    "                    validation_data = bottom_val)\n",
    "\n",
    "bottom_base_model.evaluate(bottom_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bottom_base_model.save(\"/content/drive/MyDrive/models/model_2.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foot_history = foot_base_model.fit(foot_train, \n",
    "                    epochs=5, \n",
    "                    steps_per_epoch = 2000,\n",
    "                    validation_data = foot_val)\n",
    "\n",
    "foot_base_model.evaluate(foot_test)\n",
    "\n",
    "#foot_base_model.save(\"/content/drive/MyDrive/model_2.2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
